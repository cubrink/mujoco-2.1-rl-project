@inproceedings{rl_application,
  author    = {Qiang, Wang and Zhongli, Zhan},
  booktitle = {2011 International Conference on Mechatronic Science, Electric Engineering and Computer (MEC)},
  title     = {Reinforcement learning model, algorithms and its application},
  year      = {2011},
  volume    = {},
  number    = {},
  pages     = {1143-1146},
  doi       = {10.1109/MEC.2011.6025669}
}

@online{deepmind_slides_1,
  author      = {Hado van Hasselt},
  title       = {Reinforcement Learning Lecture 1: Introduction},
  institution = {DeepMind},
  year        = {2021},
  url         = {https://storage.googleapis.com/deepmind-media/UCL%20x%20DeepMind%202021/Lecture%201%20-%20introduction.pdf}
}

@online{deepmind_slides_9,
  author      = {Hado van Hasselt},
  title       = {Reinforcement Learning Lecture 9: Policy gradients and Actor Critics},
  institution = {DeepMind},
  year        = {2021},
  url         = {https://storage.googleapis.com/deepmind-media/UCL%20x%20DeepMind%202021/Lecture%209-%20Policy%20gradients%20and%20actor%20critics.pdf}
}

@online{spinning_up_intro,
  institution = {OpenAI},
  title       = {Spinning Up: Key Concepts in RL},
  year        = {2018},
  url         = {https://spinningup.openai.com/en/latest/spinningup/rl_intro.html}
}

@online{spinning_up_taxonomy,
  institution = {OpenAI},
  title       = {Spinning Up: Kinds of RL Algorithms},
  year        = {2018},
  url         = {https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html}
}

@online{spinning_up_policy_optimization,
  institution = {OpenAI},
  title       = {Spinning Up: Intro to Policy Optimization},
  year        = {2018},
  url         = {https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html}
}

@online{spinning_up_ddpg,
  institution = {OpenAI},
  title       = {Spinning Up: Deep Deterministic Policy Gradient},
  year        = {2018},
  url         = {https://spinningup.openai.com/en/latest/algorithms/ddpg.html#}
}

@online{spinning_up_sac,
  institution = {OpenAI},
  title       = {Spinning Up: Soft Actor-Critic},
  year        = {2018},
  url         = {https://spinningup.openai.com/en/latest/algorithms/sac.html}
}

@article{REINFORCE,
  author     = {Williams, Ronald J.},
  title      = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
  year       = {1992},
  issue_date = {May 1992},
  publisher  = {Kluwer Academic Publishers},
  address    = {USA},
  volume     = {8},
  number     = {3–4},
  issn       = {0885-6125},
  url        = {https://doi.org/10.1007/BF00992696},
  doi        = {10.1007/BF00992696},
  abstract   = {This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms.},
  journal    = {Mach. Learn.},
  month      = {may},
  pages      = {229–256},
  numpages   = {28},
  keywords   = {gradient descent, mathematical analysis, Reinforcement learning, connectionist networks}
}

@article{A2C,
  author     = {Volodymyr Mnih and
                Adri{\`{a}} Puigdom{\`{e}}nech Badia and
                Mehdi Mirza and
                Alex Graves and
                Timothy P. Lillicrap and
                Tim Harley and
                David Silver and
                Koray Kavukcuoglu},
  title      = {Asynchronous Methods for Deep Reinforcement Learning},
  journal    = {CoRR},
  volume     = {abs/1602.01783},
  year       = {2016},
  url        = {http://arxiv.org/abs/1602.01783},
  eprinttype = {arXiv},
  eprint     = {1602.01783},
  timestamp  = {Mon, 13 Aug 2018 16:47:40 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/MnihBMGLHSK16.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DDPG,
  title   = {Continuous control with deep reinforcement learning},
  author  = {Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal = {arXiv preprint arXiv:1509.02971},
  year    = {2015}
}

@article{SAC1,
  author     = {Tuomas Haarnoja and
                Aurick Zhou and
                Pieter Abbeel and
                Sergey Levine},
  title      = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
                with a Stochastic Actor},
  journal    = {CoRR},
  volume     = {abs/1801.01290},
  year       = {2018},
  url        = {http://arxiv.org/abs/1801.01290},
  eprinttype = {arXiv},
  eprint     = {1801.01290},
  timestamp  = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1801-01290.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{SAC2,
  author     = {Tuomas Haarnoja and
                Aurick Zhou and
                Kristian Hartikainen and
                George Tucker and
                Sehoon Ha and
                Jie Tan and
                Vikash Kumar and
                Henry Zhu and
                Abhishek Gupta and
                Pieter Abbeel and
                Sergey Levine},
  title      = {Soft Actor-Critic Algorithms and Applications},
  journal    = {CoRR},
  volume     = {abs/1812.05905},
  year       = {2018},
  url        = {http://arxiv.org/abs/1812.05905},
  eprinttype = {arXiv},
  eprint     = {1812.05905},
  timestamp  = {Tue, 01 Jan 2019 15:01:25 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1812-05905.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{deep_rl_survey,
  author  = {Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal = {IEEE Signal Processing Magazine},
  title   = {Deep Reinforcement Learning: A Brief Survey},
  year    = {2017},
  volume  = {34},
  number  = {6},
  pages   = {26-38},
  doi     = {10.1109/MSP.2017.2743240}
}

@book{sutton2018reinforcement,
  title     = {Reinforcement learning: An introduction},
  author    = {Sutton, Richard S and Barto, Andrew G},
  year      = {2018},
  publisher = {MIT press},
  chapter   = {4}
}

@electronic{mujoco_docs,
  title  = {MuJoCo Documentation},
  author = {DeepMind},
  url    = {https://mujoco.readthedocs.io/en/latest/overview.html}
}

@electronic{gym_docs,
  title  = {Gym Documentation},
  author = {OpenAI},
  url    = {https://gym.openai.com/docs/}
}

@electronic{gym_source,
  title        = {Gym Library},
  author       = {OpenAI},
  url          = {https://github.com/openai/gym},
  howpublished = {v0.21.0}
}

@electronic{agent_videos,
  title = {mujoco-2.1-rl-project},
  author = {Brinker, Curtis and May, Tanner},
  url = {https://github.com/cubrink/mujoco-2.1-rl-project/tree/main/experiments},
}

@electronic{multiagent,
  title = {Multiagent Learning: Foundations and Recent Trends},
  author = {Albrecht, Stefano and Stone, Peter},
  year = {2017},
  url = {https://www.cs.utexas.edu/~larg/ijcai17_tutorial/multiagent_learning.pdf},
}

@article{self_driving,
  author  = {Kiran, Bangalore Ravi and Sobh, Ibrahim and Talpaert, Victor and Mannion, Patrick and Sallab, Agmad A. Al and Yogamani, Senthil and Perez, Patrick},
  journal = {IEEE Transactions on Intelligent Transportation Systems},
  title   = {Deep Reinforcement Learning for Autonomous Driving: A Survey},
  year    = {2021},
  volume  = {99},
  pages   = {1-18},
  doi     = {10.1109/TITS.2021.3054625}
}
